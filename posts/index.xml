<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Posts on Don't Repeat Yourself</title><link>https://krokotsch.eu/posts/</link><description>Recent content in Posts on Don't Repeat Yourself</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 30 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://krokotsch.eu/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Compose Datasets, Don't Inherit Them</title><link>https://krokotsch.eu/posts/compose-datasets/</link><pubDate>Sun, 30 Jan 2022 00:00:00 +0000</pubDate><guid>https://krokotsch.eu/posts/compose-datasets/</guid><description>In relatively young disciplines, like deep learning, people tend to leave behind old principles. Sometimes this is a good thing because times have changed and old truths, i.e. over-completeness being a bad thing, have to go. Other times, such old principles stick around for a reason and still people over-eagerly try to throw them out of the window. I am no exception in this regard so let me tell you how I &amp;ldquo;re-learned&amp;rdquo; the tried and true design pattern of &amp;ldquo;Composition over Inheritance&amp;rdquo;.</description></item><item><title>About Copying Blindly - Insights of the One-Eyed Person</title><link>https://krokotsch.eu/posts/about-copying-blindly/</link><pubDate>Wed, 07 Apr 2021 00:00:00 +0000</pubDate><guid>https://krokotsch.eu/posts/about-copying-blindly/</guid><description>Today I have no fancy project and no shiny GitHub repository to show because today I want to talk about my research. As some may read in my bio, I am doing my PhD in the field of predictive maintenance (PDM). This field is directly adjacent to machine learning and fell, like many others, into the grasp of the deep learning hype. Unfortunately, long series of sensor readings are not as interesting to look at as images or intuitively understood as natural language, so PDM is not as present in the mind of the general ML crowd.</description></item><item><title>The Great Autoencoder Bake Off</title><link>https://krokotsch.eu/posts/ae-bakeoff/</link><pubDate>Sun, 24 Jan 2021 00:00:00 +0000</pubDate><guid>https://krokotsch.eu/posts/ae-bakeoff/</guid><description>&amp;ldquo;Another article comparing types of autoencoders?&amp;quot;, you may think. &amp;ldquo;There are already so many of them!&amp;quot;, you may think. &amp;ldquo;How does he know what I am thinking?!&amp;quot;, you may think. While the first two statements are certainly appropriate reactions - and the third a bit paranoid - let me explain my reasons for this article.
There are indeed articles comparing some autoencoders to each other (e.g. [1], [2], [3]), I found them lacking something.</description></item><item><title>Make DL4J Readable Again</title><link>https://krokotsch.eu/posts/kotlin-dsl-for-dl4j/</link><pubDate>Sun, 20 Sep 2020 00:00:00 +0000</pubDate><guid>https://krokotsch.eu/posts/kotlin-dsl-for-dl4j/</guid><description>A while ago, I stumbled upon an article about the language Kotlin and how to use it for Data Science. I found it interesting, as some of Python&amp;rsquo;s quirks were starting to bother me and I wanted to try something new. A day later, I had completed the Kotlin tutorials using Kotlin Koans in IntelliJ IDEA (which is an excellent way to get started with Kotlin). Hungry to test out my new language skills, I looked around for a project idea.</description></item><item><title>How to Trust Your Deep Learning Code</title><link>https://krokotsch.eu/posts/deep-learning-unit-tests/</link><pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate><guid>https://krokotsch.eu/posts/deep-learning-unit-tests/</guid><description>Deep learning is a discipline where the correctness of code is hard to assess. Random initialization, huge datasets and limited interpretability of weights mean that finding the exact issue of why your model is not training, is trial-and-error most times. In classical software development, automated unit tests are the bread and butter for determining if your code does what it is supposed to do. It helps the developer to trust their code and be confident when introducing changes.</description></item></channel></rss>